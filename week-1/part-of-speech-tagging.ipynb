{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:15:35.918526Z","iopub.execute_input":"2025-02-10T17:15:35.918869Z","iopub.status.idle":"2025-02-10T17:15:43.185476Z","shell.execute_reply.started":"2025-02-10T17:15:35.918834Z","shell.execute_reply":"2025-02-10T17:15:43.184276Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.28.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# import library\nfrom typing import List\nimport numpy as np\nimport torch\nimport evaluate\nfrom sklearn.model_selection import train_test_split\nimport nltk\nnltk.download('treebank')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:15:43.186551Z","iopub.execute_input":"2025-02-10T17:15:43.186879Z","iopub.status.idle":"2025-02-10T17:16:18.527515Z","shell.execute_reply.started":"2025-02-10T17:15:43.186847Z","shell.execute_reply":"2025-02-10T17:16:18.526597Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package treebank to /usr/share/nltk_data...\n[nltk_data]   Package treebank is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# load tree bank dataset\ntagged_sentences = nltk.corpus.treebank.tagged_sents()\nprint(\"Number of samples:\", len(tagged_sentences))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:18.528643Z","iopub.execute_input":"2025-02-10T17:16:18.529168Z","iopub.status.idle":"2025-02-10T17:16:19.838965Z","shell.execute_reply.started":"2025-02-10T17:16:18.529145Z","shell.execute_reply":"2025-02-10T17:16:19.838078Z"}},"outputs":[{"name":"stdout","text":"Number of samples: 3914\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tagged_sentences[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:19.839888Z","iopub.execute_input":"2025-02-10T17:16:19.840141Z","iopub.status.idle":"2025-02-10T17:16:19.847390Z","shell.execute_reply.started":"2025-02-10T17:16:19.840110Z","shell.execute_reply":"2025-02-10T17:16:19.846405Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[('Pierre', 'NNP'),\n ('Vinken', 'NNP'),\n (',', ','),\n ('61', 'CD'),\n ('years', 'NNS'),\n ('old', 'JJ'),\n (',', ','),\n ('will', 'MD'),\n ('join', 'VB'),\n ('the', 'DT'),\n ('board', 'NN'),\n ('as', 'IN'),\n ('a', 'DT'),\n ('nonexecutive', 'JJ'),\n ('director', 'NN'),\n ('Nov.', 'NNP'),\n ('29', 'CD'),\n ('.', '.')]"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# save sentences and tags\nsentences, sentence_tags =[], []\n\nfor tagged_sentence in tagged_sentences:\n    sentence, tags = zip(*tagged_sentence)\n    sentences.append([word.lower() for word in sentence])\n    sentence_tags.append([tag for tag in tags])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:19.848182Z","iopub.execute_input":"2025-02-10T17:16:19.848461Z","iopub.status.idle":"2025-02-10T17:16:20.893447Z","shell.execute_reply.started":"2025-02-10T17:16:19.848439Z","shell.execute_reply":"2025-02-10T17:16:20.892505Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Create label mappings\nunique_labels = sorted(set(label for sublist in sentence_tags for label in sublist))\nlabel2id = {label: idx for idx, label in enumerate(unique_labels)}\nlabel2id[\"0\"] = len(label2id)  # Padding label ID\nid2label = {i: l for l, i in label2id.items()}\nprint(id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:20.895720Z","iopub.execute_input":"2025-02-10T17:16:20.895983Z","iopub.status.idle":"2025-02-10T17:16:20.909533Z","shell.execute_reply.started":"2025-02-10T17:16:20.895962Z","shell.execute_reply":"2025-02-10T17:16:20.908628Z"}},"outputs":[{"name":"stdout","text":"{0: '#', 1: '$', 2: \"''\", 3: ',', 4: '-LRB-', 5: '-NONE-', 6: '-RRB-', 7: '.', 8: ':', 9: 'CC', 10: 'CD', 11: 'DT', 12: 'EX', 13: 'FW', 14: 'IN', 15: 'JJ', 16: 'JJR', 17: 'JJS', 18: 'LS', 19: 'MD', 20: 'NN', 21: 'NNP', 22: 'NNPS', 23: 'NNS', 24: 'PDT', 25: 'POS', 26: 'PRP', 27: 'PRP$', 28: 'RB', 29: 'RBR', 30: 'RBS', 31: 'RP', 32: 'SYM', 33: 'TO', 34: 'UH', 35: 'VB', 36: 'VBD', 37: 'VBG', 38: 'VBN', 39: 'VBP', 40: 'VBZ', 41: 'WDT', 42: 'WP', 43: 'WP$', 44: 'WRB', 45: '``', 46: '0'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_sentences, test_sentences, train_tags, test_tags = train_test_split(\n    sentences,\n    sentence_tags,\n    test_size =0.3\n)\n\nvalid_sentences, test_sentences, valid_tags, test_tags = train_test_split(\n    test_sentences,\n    test_tags,\n    test_size =0.5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:20.910646Z","iopub.execute_input":"2025-02-10T17:16:20.910919Z","iopub.status.idle":"2025-02-10T17:16:20.939384Z","shell.execute_reply.started":"2025-02-10T17:16:20.910900Z","shell.execute_reply":"2025-02-10T17:16:20.938670Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# tokenization\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\n\nmodel_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    use_fast=True\n)\n\n\nMAX_LEN = 256\nclass PosTagging_Dataset(Dataset):\n    def __init__(self ,\n        sentences: List[List[str]],\n        tags: List[List[str]],\n        tokenizer,\n        label2id,\n        max_len=MAX_LEN\n    ):\n        super().__init__ ()\n        self.sentences = sentences\n        self.tags = tags\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.label2id = label2id\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self , idx):\n        input_token = self.sentences[idx]\n        label_token = self.tags[idx]\n\n        input_token = self.tokenizer.convert_tokens_to_ids(input_token)\n        attention_mask = [1] * len(input_token)\n        labels = [self.label2id[token] for token in label_token]\n\n        return {\n            \"input_ids\": self.pad_and_truncate(input_token, pad_id=self.tokenizer.pad_token_id),\n            \"labels\": self.pad_and_truncate(labels, pad_id=label2id[\"0\"]),\n            \"attention_mask\": self.pad_and_truncate(attention_mask , pad_id =0)\n        }\n\n    def pad_and_truncate(self, inputs: List[int], pad_id: int):\n        if len(inputs) < self.max_len:\n            padded_inputs = inputs + [pad_id] * (self.max_len - len(inputs))\n        else:\n            padded_inputs = inputs[:self.max_len]\n        return torch.as_tensor(padded_inputs)\n\n\ntrain_dataset = PosTagging_Dataset(train_sentences, train_tags, tokenizer, label2id)\nval_dataset = PosTagging_Dataset(valid_sentences, valid_tags, tokenizer, label2id)\ntest_dataset = PosTagging_Dataset(test_sentences, test_tags, tokenizer, label2id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:20.940252Z","iopub.execute_input":"2025-02-10T17:16:20.940543Z","iopub.status.idle":"2025-02-10T17:16:22.000970Z","shell.execute_reply.started":"2025-02-10T17:16:20.940523Z","shell.execute_reply":"2025-02-10T17:16:22.000251Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e657396d35914767b98f855a387343aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d1706402a6944fa82ffc51a226e8dab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c051f2a23e4d6ea5e82e5c4a38c13c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a7e063ede0f4daabc7fa5a87f265b11"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"next(iter(iter(train_dataset)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:22.001736Z","iopub.execute_input":"2025-02-10T17:16:22.001964Z","iopub.status.idle":"2025-02-10T17:16:22.092175Z","shell.execute_reply.started":"2025-02-10T17:16:22.001945Z","shell.execute_reply":"2025-02-10T17:16:22.091477Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  100,   100,   115, 10155,   100, 53147,   115, 10114, 16068, 12748,\n         39282, 10106,   100, 10407, 45751, 12742,   100, 42919,   117, 10319,\n           100,   100, 10842, 10114, 65036,   119,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]),\n 'labels': tensor([23, 38,  5, 14, 23, 37,  5, 33, 35, 20, 23, 14, 21, 10, 23, 36, 21, 22,\n          3, 41,  5, 36, 10, 33, 10,  7, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n         46, 46, 46, 46]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\n\nmodel_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    num_labels=len(label2id),\n    ignore_mismatched_sizes=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:22.093046Z","iopub.execute_input":"2025-02-10T17:16:22.093375Z","iopub.status.idle":"2025-02-10T17:16:28.741777Z","shell.execute_reply.started":"2025-02-10T17:16:22.093344Z","shell.execute_reply":"2025-02-10T17:16:28.740833Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/712M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c2f9defea2a4d54b92f2a204172b800"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at QCRI/bert-base-multilingual-cased-pos-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at QCRI/bert-base-multilingual-cased-pos-english and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([46, 768]) in the checkpoint and torch.Size([47, 768]) in the model instantiated\n- classifier.bias: found shape torch.Size([46]) in the checkpoint and torch.Size([47]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\nignore_label = len(label2id)\n\ndef compute_metrics(eval_pred):\n    predictions , labels = eval_pred\n    mask = labels != ignore_label\n    predictions = np.argmax(predictions , axis=-1)\n    return accuracy.compute(predictions=predictions[mask], references=labels[mask])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:28.743022Z","iopub.execute_input":"2025-02-10T17:16:28.743372Z","iopub.status.idle":"2025-02-10T17:16:29.100178Z","shell.execute_reply.started":"2025-02-10T17:16:28.743337Z","shell.execute_reply":"2025-02-10T17:16:29.099279Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf7db2507b14104aeae9bf60b80bda0"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:29.101077Z","iopub.execute_input":"2025-02-10T17:16:29.101411Z","iopub.status.idle":"2025-02-10T17:16:29.105061Z","shell.execute_reply.started":"2025-02-10T17:16:29.101382Z","shell.execute_reply":"2025-02-10T17:16:29.104322Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:29.105927Z","iopub.execute_input":"2025-02-10T17:16:29.106151Z","iopub.status.idle":"2025-02-10T17:16:29.142932Z","shell.execute_reply.started":"2025-02-10T17:16:29.106134Z","shell.execute_reply":"2025-02-10T17:16:29.142059Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Embedding(119547, 768, padding_idx=0)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"out_dir\",\n    learning_rate =1e-5,\n    per_device_train_batch_size =16,\n    per_device_eval_batch_size =16,\n    num_train_epochs =9,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n    model=model ,\n    args=training_args ,\n    train_dataset=train_dataset ,\n    eval_dataset=val_dataset ,\n    tokenizer = tokenizer ,\n    compute_metrics=compute_metrics ,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:16:29.143942Z","iopub.execute_input":"2025-02-10T17:16:29.144285Z","iopub.status.idle":"2025-02-10T17:29:54.472732Z","shell.execute_reply.started":"2025-02-10T17:16:29.144239Z","shell.execute_reply":"2025-02-10T17:29:54.472016Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n<ipython-input-14-575789a2b5a9>:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='774' max='774' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [774/774 13:18, Epoch 9/9]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.158819</td>\n      <td>0.968650</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.089101</td>\n      <td>0.978579</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.067945</td>\n      <td>0.982172</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.058019</td>\n      <td>0.984954</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.052765</td>\n      <td>0.986285</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.168500</td>\n      <td>0.049531</td>\n      <td>0.987057</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.168500</td>\n      <td>0.047996</td>\n      <td>0.987236</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.168500</td>\n      <td>0.046635</td>\n      <td>0.987662</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.168500</td>\n      <td>0.046404</td>\n      <td>0.987729</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=774, training_loss=0.12685396381742886, metrics={'train_runtime': 801.953, 'train_samples_per_second': 30.739, 'train_steps_per_second': 0.965, 'total_flos': 3221923456654848.0, 'train_loss': 0.12685396381742886, 'epoch': 9.0})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# tokenization\ntest_sentence = \"We are exploring the topic of deep learning\"\ninput = torch.as_tensor([ tokenizer.convert_tokens_to_ids(test_sentence.split())])\ninput = input.to(\"cuda\")\n\n# prediction\noutputs = model(input)\n_, preds = torch.max(outputs.logits , -1)\npreds = preds.cpu().numpy()\n\n# decode\npred_tags = \"\"\nfor pred in preds[0]:\n    pred_tags += id2label[pred] + \" \"\n\npred_tags ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:31:22.679720Z","iopub.execute_input":"2025-02-10T17:31:22.680096Z","iopub.status.idle":"2025-02-10T17:31:22.703176Z","shell.execute_reply.started":"2025-02-10T17:31:22.680068Z","shell.execute_reply":"2025-02-10T17:31:22.702505Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'DT VBP VBG DT NN IN JJ NN '"},"metadata":{}}],"execution_count":20}]}